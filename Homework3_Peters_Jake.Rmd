---
title: "Homework3_Peters_Jake"
author: "Jake Peters"
date: "1/24/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('dslabs')
library('caret')
```
P1
ISL Section 2.4
#2
Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p.

(a) We collect a set of data on the top 500 firms in the US. For each
firm we record profit, number of employees, industry and the
CEO salary. We are interested in understanding which factors
affect CEO salary.

This problem is regression because you are analyzing the CEO salary, which is a continuous quantity (dollars). We are most interested in inference because we want to look at the relationships between the predictors and a response, which is the salary. p, the # of predictors, is 3 (profit, emploees, industry), and n, # of observations, is 500 firms in US

(b) We are considering launching a new product and wish to know
whether it will be a success or a failure. We collect data on 20
similar products that were previously launched. For each product we have recorded whether it was a success or failure, price
charged for the product, marketing budget, competition price,
and ten other variables.

This is classification because you are predicting a discrete outcome or label (success or failure of a product). We are more interested in prediction because we care most about being able to predict success or failure of the product, not the relationship between the variables. n is 20 products, p is 13 (price of product, marketing budget, competition price, and 10 other variables)

(c) We are interested in predicting the % change in the USD/Euro
exchange rate in relation to the weekly changes in the world
stock markets. Hence we collect weekly data for all of 2012. For
each week we record the % change in the USD/Euro, the %
change in the US market, the % change in the British market,
and the % change in the German market.

This is regression, because we are trying to predict continuous quantity of change of money. This is Prediction because you are trying to predict the % change in the exchange rate. The n is 52 weeks of data, p 3 = is US %change, British %change, German %change


# 4. 
You will now think of some real-life applications for statistical learning.

(a) Describe three real-life applications in which classification might
be useful. Describe the response, as well as the predictors. Is the
goal of each application inference or prediction? Explain your
answer.

One is trying to predict whether an ethnic population has diabetes or no diabetes. Response is diabetes, and the predictors could be weight, alcohol intake, sugar intake, and age. The goal is prediction, because we are trying to predict whether the patient has diabetes for preventative medicine.

Another is trying to predict whether a character from a TV show will live or die in a tv series. The response will be death, and the predictors are age of character, whether the character is a main character, and if they are a villain or hero. This is prediction, because we are trying to predict death of a character.

A last is a dataset of a group who either have throat cancer or not. This is the response and the predictors are cigarette smoking, age, weight, tobacco intake, and asbestos exposure in blood. This is inference because we are trying to discover what variable most contributes to whether a person has throat cancer. 


(b) Describe three real-life applications in which regression might
be useful. Describe the response, as well as the predictors. Is the
goal of each application inference or prediction? Explain your
answer.

One is a housing dataset with sale price of the house. This is the response and the predictors could be square feet, census tract, and number of bedrooms. This is inference because we are trying to see the relationships between sale price and the response variables. 

Another is student college GPA (response) based on predictors like hours spent on HW, high school GPA, and hours of sleep. This is inference because we are trying to see the relationsip between GPA and various lifestyle factors.

A last is NBA player draft position (response) based on predictors like PPG in college, Age at draft time, and school attended. This is prediction because we are trying to predict draft position based on the predictor variables to get better ideas of where to draft a player, or for betting purposes. 

(c) Describe three real-life applications in which cluster analysis
might be useful.

One is where you need to organize houses in a dataset to create a neighborhood metric. So you would need to organize them by location and price for example.

Another is where you have to cluster number of cancer cells in an organ based on starting cells and time elapsed. This is so you can build clusters for a model to predict growth of the cells.

A last is to cluster groups of people based on their industry, for example clustering by fast food industry or nonprofit organization. This is to subset people for various possibilites such as salary, or mortality rate.

## Homework Part 2

The BRCA dataset provides biopsy features for classification of 569 malignant (cancer) and benign (not cancer) breast masses. Features were computationally extracted from digital images of fine needle aspirate biopsy slides.
Features correspond to properties of cell nuclei, such as size, shape and regularity. The mean,
standard error, and worst value of each of 10 nuclear parameters is reported for a total of 30 features.
This is a classic dataset for training and benchmarking machine learning algorithms.

* y. The outcomes. A factor with two levels denoting whether a mass is malignant ("M") or
benign ("B").

* x. The predictors. A matrix with the mean, standard error and worst value of each of 10
nuclear measurements on the slide, for 30 total features per biopsy. We will focus on the mean nucleus radius (mean of distances from center to points on perimeter).

For this homework, you will use a single predictor (mean_radius) and a cutoff to predict whether the mass is malignant ("M") or benign ("B"). For this scenario, malignant is the positive class.

```{r}
data(brca)
predictors = data.frame(brca$x)
brca_data = data.frame(mean_radius = predictors$radius_mean, M_or_B = fct_relevel(brca$y, c("M","B"))) # relevel y to make M the first/positive class
set.seed(42)
test_index <- createDataPartition(brca_data$M_or_B, p = 0.25, list = FALSE)
test_brca <- brca_data[test_index,]
train_brca <- brca_data[-test_index,]

ggplot(train_brca)+
  geom_density(mapping = aes(x = mean_radius, fill = M_or_B), alpha = 0.5)
brca_data
train_brca
```

### Problem 1

Create a plot of the accuracy (on the training set) for cutoff values from 10 to 17.

```{r}
## Your code goes here.


cutoff <- seq(10,17,0.5)
accuracy <- map_dbl(cutoff, function(x){
  y_hat_tumor <- if_else(train_brca$mean_radius > x, "M", "B")
  mean(y_hat_tumor == train_brca$M_or_B)
})

ggplot(mapping = aes(x = cutoff, y = accuracy)) +
  geom_point() +
  geom_line()


```

### Problem 2

What is the maximum accuracy? At what cutoff? For the cutoff that gives max accuracy, compute the confusion matrix, sensitivity and specificity (on the test set).

```{r}
## Your code goes here.
max(accuracy)

best_cutoff_acc <- cutoff[which.max(accuracy)]
best_cutoff_acc
y_hat_tumor <- if_else(test_brca$mean_radius > best_cutoff_acc, "M", "B")
mean(y_hat_tumor == test_brca$M_or_B)
cm <- confusionMatrix(data = factor(y_hat_tumor, levels = c("M", "B")),
                      reference = test_brca$M_or_B,
                      positive = "M")
cm

```
The max accuracy is .899 at cutoff of 15. The sensitivity is .698 and the specificity is .955.

### Problem 3

Create a plot of the F~1~ score (on the training set) for cutoff values from 10 to 17.

```{r}
## Your code goes here.
cutoff <- seq(10,17,0.5)
F_1_second <- map_dbl(cutoff, function(x){
  y_hat <- if_else(train_brca$mean_radius > x, "M", "B")
  F_meas(data = factor(y_hat, levels = c("M","B")), reference = train_brca$M_or_B, beta = 1)
})

ggplot(mapping = aes(x = cutoff, y = F_1_second)) +
  geom_point() +
  geom_line()

```

### Problem 4

What is the maximum F~1~ score? At what cutoff? For the cutoff that gives max F~1~ score, compute the confusion matrix, sensitivity and specificity (on the test set).

```{r}
## Your code goes here.
max(na.omit(F_1_second))
best_cutoff_acc <- cutoff[which.max(F_1_second)]
best_cutoff_acc
y_hat_tumor <- if_else(test_brca$mean_radius > best_cutoff_acc, "M", "B")
mean(y_hat_tumor == test_brca$M_or_B)
cm <- confusionMatrix(data = factor(y_hat_tumor, levels = c("M", "B")),
                      reference = test_brca$M_or_B,
                      positive = "M")
cm

```
The max is .852 at a cutoff of 15. The specificity is .96 and the sensitivity is .698.

### Problem 5

After thinking about the consequences, you decide that not diagnosing someone with cancer (false negative) is twice as worse than accidentally diagnosing someone who doesn't have cancer (false positive). Now examine the F~$\beta$~ score with $\beta = 2$. Create a plot of the F~2~ score (on the training set) for cutoff values from 10 to 17.

```{r}
## Your code goes here.

cutoff <- seq(10,17,0.5)
F_2 <- map_dbl(cutoff, function(x){
  y_hat <- if_else(train_brca$mean_radius > x, "M", "B")
  F_meas(data = factor(y_hat, levels = c("M","B")), reference = train_brca$M_or_B, beta = 2)
})

ggplot(mapping = aes(x = cutoff, y = F_2)) +
  geom_point() +
  geom_line()
```

### Problem 6

What is the maximum F~2~ score? At what cutoff? For the cutoff that gives max F~2~ score, compute the confusion matrix, sensitivity and specificity (on the test set). Contrast the performance of this model compared to the previous models (specifically look at the numbers of false positive and false negatives).

```{r}
## Your code goes here.
max(na.omit(F_2))
best_cutoff_acc <- cutoff[which.max(F_2)]
best_cutoff_acc
y_hat_tumor <- if_else(test_brca$mean_radius > best_cutoff_acc, "M", "B")
mean(y_hat_tumor == test_brca$M_or_B)
cm <- confusionMatrix(data = factor(y_hat_tumor, levels = c("M", "B")),
                      reference = test_brca$M_or_B,
                      positive = "M")
cm


```
The max is .86, the cutoff is 13.5. The specificity is .811 and the sensitivity is .85. The sensitivity for this model is much higher than the beta 1 model, and the specificity for this model is lower than the beta 1 model. This is because this model penalizes false negatives, aka Malignant tumors being falsely classified as benign. We decided that was worse, so we are penalizing false negatives with a beta of 2. Malignant tumors falsely negated could kill people. We sacrifice specificity and accuracy for sensitivity. In this C matrix, there are much less false negatives than false positives, so our model is doing its job. This is in contrast to the beta 1 model, which had more false negatives.
